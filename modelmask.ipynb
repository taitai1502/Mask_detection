{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model1 = load_model('F:/Project_Mask_NoMask/model1.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0 28104    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 28104  100 28104    0     0  46411      0 --:--:-- --:--:-- --:--:-- 46529\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  2 10.1M    2  216k    0     0   268k      0  0:00:38 --:--:--  0:00:38  268k\n",
      " 25 10.1M   25 2630k    0     0  1406k      0  0:00:07  0:00:01  0:00:06 1407k\n",
      " 51 10.1M   51 5382k    0     0  1911k      0  0:00:05  0:00:02  0:00:03 1911k\n",
      " 74 10.1M   74 7718k    0     0  2026k      0  0:00:05  0:00:03  0:00:02 2027k\n",
      "100 10.1M  100 10.1M    0     0  2209k      0  0:00:04  0:00:04 --:--:-- 2210k\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\n",
    "!curl -O https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading model...\")\n",
    "prototxt = 'deploy.prototxt'\n",
    "model = 'res10_300x300_ssd_iter_140000.caffemodel'\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    " \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "\n",
    "        # Excute frame here\n",
    "        #frame = cv2.imread(frame)\n",
    "        \n",
    "        frame = imutils.resize(frame, width=400)\n",
    "        (h, w) = frame.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        for i in range(0, detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > 0.5:\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                text = \"{:.2f}%\".format(confidence * 100)\n",
    "                y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "                cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
    "                minX, maxX = min(startX, endX), max(startX, endX)\n",
    "                minY, maxY = min(startY, endY), max(startY, endY)\n",
    "                face = frame[minY:maxY, minX:maxX].copy()\n",
    "                img = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "                img = cv2.resize(img,(128,128))\n",
    "                img = np.array([img/255.])\n",
    "                y_hat = model1.predict(img)\n",
    "                for i in range(y_hat.shape[1]):\n",
    "                    max_value=np.max(y_hat)\n",
    "                    if y_hat[0][i]==max_value:\n",
    "                        y_hat[0][i]=1\n",
    "                    else:\n",
    "                        y_hat[0][i]=0\n",
    "                predic = np.argmax(y_hat, axis=1)\n",
    "                if predic == 0:\n",
    "                    cv2.putText(frame,\"0\", (startX, y),cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "                if predic ==1:\n",
    "                    cv2.putText(frame,\"1\", (startX, y),cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "                else:\n",
    "                    cv2.putText(frame,\"2\", (startX, y),cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "        \n",
    "        cv2.imshow(\"frame\", frame)\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "\n",
    "        if key == 27:\n",
    "\n",
    "            break\n",
    "\n",
    " \n",
    "\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import shutil\n",
    "import cv2 \n",
    "from PIL import Image\n",
    "import PIL\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import warnings\n",
    "# Ignore waring\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_list = glob.glob(\"/content/happy/*\")\n",
    "X=[]\n",
    "name_label=[]\n",
    "for name in name_list:\n",
    "  name_label.append(0)\n",
    "\n",
    "  img =cv2.imread(name)\n",
    "  img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "  img = cv2.resize(img,(50,50))\n",
    "\n",
    "  X.append((img))\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_list = glob.glob(\"/content/sad/*\")\n",
    "\n",
    "for name in name_list:\n",
    "  name_label.append(1)\n",
    "\n",
    "  img = cv2.imread(name)\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  img = cv2.resize(img, (50,50))\n",
    "\n",
    "  X.append((img))\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mask_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m X \u001b[39m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m y \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfor\u001b[39;00m i, path \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(mask_path):\n\u001b[0;32m      5\u001b[0m   \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m glob\u001b[39m.\u001b[39mglob(train_path \u001b[39m+\u001b[39m path):\n\u001b[0;32m      6\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(name)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mask_path' is not defined"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i, path in enumerate(mask_path):\n",
    "\n",
    "  for name in glob.glob(train_path + path):\n",
    "    img = cv2.imread(name)\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    #img = img.convert('RGB')\n",
    "    img = cv2.resize(img,(128,128))\n",
    "    X.append((img))\n",
    "    y.append(i)\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)/255.\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].shape\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(128,128,1))\n",
    "\n",
    "x = Conv2D(filters=32 ,kernel_size=3, activation='relu')(inp)\n",
    "x = MaxPooling2D(pool_size= (2,2))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = Conv2D(filters=64 ,kernel_size=3, activation='relu')(inp)\n",
    "x = MaxPooling2D(pool_size= (2,2))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = Conv2D(filters=128 ,kernel_size=3, activation='relu')(inp)\n",
    "x = MaxPooling2D(pool_size= (2,2))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = Conv2D(filters=128 ,kernel_size=3, activation='relu')(inp)\n",
    "x = MaxPooling2D(pool_size= (2,2))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(units = 128,activation='relu')(x)\n",
    "x = Dense(units = 64,activation='relu')(x)\n",
    "x = Dense(units = 2)(x)\n",
    "\n",
    "cnn = Model(inputs = inp , outputs = x )\n",
    "\n",
    "\n",
    "img1 = Input(shape=(128,128,1))\n",
    "img2 = Input(shape=(128,128,1))\n",
    "\n",
    "f1 = cnn(img1)\n",
    "f2 = cnn(img2)\n",
    "\n",
    "d = K.sqrt(K.sum(K.square(f1-f2),axis =1 ,keepdims=True))\n",
    "\n",
    "model = Model(inputs = (img1,img2),outputs = d)\n",
    "model.summary()\n",
    "cnn.summary()\n",
    "\n",
    "def loss(y_true,y_pred):\n",
    "    proba = K.exp(-K.square(y_pred))\n",
    "    return -K.mean(y_true*K.log(proba)+(1-y_true)*K.log(1-proba))\n",
    "\n",
    "def loss1(y_true,y_pred):\n",
    "    return K.mean(y_true*K.square(y_pred)+(1-y_true)*K.square(K.maximum(1.0-y_pred,0)))\n",
    "\n",
    "model.compile(optimizer='adam',loss = loss1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "def generator(X,y,k=8):\n",
    "    unique_labels = np.unique(y)\n",
    "    while True:\n",
    "        X1 = []\n",
    "        X2 = []\n",
    "        y_batch = []\n",
    "        for label in unique_labels :\n",
    "            label_idx = np.where(y==label)[0]\n",
    "            other_labels =set(unique_labels)-{label}\n",
    "            for i in range(k):\n",
    "                i1 = np.random.choice(label_idx)\n",
    "                i2 = np.random.choice(label_idx)\n",
    "                # i1 must be different from i2\n",
    "                \n",
    "                while i1 == i2 :\n",
    "                    #i1 = np.random.choice(label_idx)\n",
    "                    i2 = np.random.choice(label_idx)\n",
    "                    \n",
    "                # create positive example \n",
    "                X1.append(X[i1][:,:,None])\n",
    "                X2.append(X[i2][:,:,None])\n",
    "                y_batch.append(1.0)\n",
    "                \n",
    "                # create negative example\n",
    "                i1 = np.random.choice(label_idx)\n",
    "                my_label = np.random.choice(list(other_labels))\n",
    "                i2 = np.random.choice(list(np.where(y == my_label)[0]))\n",
    "                X1.append(X[i1][:,:,None])\n",
    "                X2.append(X[i2][:,:,None])\n",
    "                y_batch.append(0.0)\n",
    "        \n",
    "        yield [np.array(X1)/255.,np.array(X2)/255.],np.array(y_batch) \n",
    "            \n",
    "                \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(generator(X_train,y_train,k=16),\n",
    "                    steps_per_epoch = 5,\n",
    "                    epochs = 10,\n",
    "                    validation_data = generator(X_test,y_test,k=8),\n",
    "                    validation_steps= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test_scaled, Y_test)\n",
    "print('Test Accuracy =', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = history\n",
    "\n",
    "# plot the loss value\n",
    "plt.plot(h.history['loss'], label='train loss')\n",
    "plt.plot(h.history['val_loss'], label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot the accuracy value\n",
    "plt.plot(h.history['acc'], label='train accuracy')\n",
    "plt.plot(h.history['val_acc'], label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = history\n",
    "\n",
    "# plot the loss value\n",
    "plt.plot(h.history['loss'], label='train loss')\n",
    "plt.plot(h.history['val_loss'], label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot the accuracy value\n",
    "plt.plot(h.history['acc'], label='train accuracy')\n",
    "plt.plot(h.history['val_acc'], label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_path = input('Path of the image to be predicted: ')\n",
    "\n",
    "input_image = cv2.imread(input_image_path)\n",
    "\n",
    "cv2_imshow(input_image)\n",
    "\n",
    "input_image_resized = cv2.resize(input_image, (128,128))\n",
    "\n",
    "input_image_scaled = input_image_resized/255\n",
    "\n",
    "input_image_reshaped = np.reshape(input_image_scaled, [1,128,128,3])\n",
    "\n",
    "input_prediction = model.predict(input_image_reshaped)\n",
    "\n",
    "print(input_prediction)\n",
    "\n",
    "\n",
    "input_pred_label = np.argmax(input_prediction)\n",
    "\n",
    "print(input_pred_label)\n",
    "\n",
    "\n",
    "if input_pred_label == 1:\n",
    "\n",
    "  print('The person in the image is wearing a mask')\n",
    "\n",
    "else:\n",
    "\n",
    "  print('The person in the image is not wearing a mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_path = input('Path of the image to be predicted: ')\n",
    "\n",
    "input_image = cv2.imread(input_image_path)\n",
    "\n",
    "cv2_imshow(input_image)\n",
    "\n",
    "input_image_resized = cv2.resize(input_image, (128,128))\n",
    "\n",
    "input_image_scaled = input_image_resized/255\n",
    "\n",
    "input_image_reshaped = np.reshape(input_image_scaled, [1,128,128,3])\n",
    "\n",
    "input_prediction = model.predict(input_image_reshaped)\n",
    "\n",
    "print(input_prediction)\n",
    "\n",
    "\n",
    "input_pred_label = np.argmax(input_prediction)\n",
    "\n",
    "print(input_pred_label)\n",
    "\n",
    "\n",
    "if input_pred_label == 1:\n",
    "\n",
    "  print('The person in the image is wearing a mask')\n",
    "\n",
    "else:\n",
    "\n",
    "  print('The person in the image is not wearing a mask')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
